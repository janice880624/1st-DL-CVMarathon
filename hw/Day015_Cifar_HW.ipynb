{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.22.1-cp36-cp36m-macosx_10_6_intel.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=c8ce776112ff883d03385f1c831753e222235c19f2c21535fddb0535fe0b53f5\n",
      "  Stored in directory: /Users/janice/Library/Caches/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.1 sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, Dropout, Dense\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) # Output：(50000, 32, 32, 3)\n",
    "\n",
    "# Normalize Data function\n",
    "def normalize(x_train,x_test):\n",
    "    mean = np.mean(x_train, axis=(0,1,2,3))\n",
    "    standardization = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "    x_train = (x_train - mean) / (standardization + 1e-7)\n",
    "    x_test = (x_test - mean) / (standardization + 1e-7) \n",
    "    return x_train, x_test, mean, standardization\n",
    "    \n",
    "    \n",
    "# Normalize Training and Test set    \n",
    "x_train, x_test, mean_train, standardization_train = normalize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3)))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#FC\n",
    "model.add(Dense(output_dim=100, activation=\"relu\"))\n",
    "\n",
    "#輸出\n",
    "model.add(Dense(output_dim=10, activation='sigmoid'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization\n",
    "x_predict = (np.zeros(shape=(1, 32, 32, 3)) - mean_train) / (stardardization_train + 1e-7) \n",
    "model.predict(x_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
